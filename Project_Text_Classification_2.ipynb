{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project in Web Intelligence: Text Classification\n",
    "==========\n",
    "In the following Scikit Learn is used to classify a set of articles, where 150 are classified as category 'Video Games', and 150 as category 'Programming'.\n",
    "\n",
    "The csv-file is read, then split into training and test sets. Default test size 0.25 is used.\n",
    "\n",
    "First algorithm used is:\n",
    "Naive Bayes Multinomial, MultinomialNB().\n",
    "------\n",
    "Every article is represented as a string of words. This string is vectorized using Scikit Learn's CountVectorizer, so that it can be handled by the algorithm.\n",
    "\n",
    "The model is then fitted on the training data.\n",
    "It is also evaluated on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "# import dataset\n",
    "df = pd.read_csv(\"./wikipedia_300/wikipedia_300.csv\")\n",
    "\n",
    "# test_size default is 25% (0.25)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Category'], random_state = 0)\n",
    "\n",
    "#1. Naive Bayes with no term frequency or inverse document frequency adjustments\n",
    "\n",
    "# Extract word counts as features and vectorize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# min_df=1 means ignore words with word count less than one\n",
    "count_vect = CountVectorizer(min_df=1)\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_counts, y_train)\n",
    "clf.score(X_train_counts, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 43017)\n",
      "(225, 43017)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9911111111111112"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Naive Bayes with term frequency and inverse document frequency adjustments\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Category'], random_state = 0)\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "clf_tfidf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "clf_tfidf.score(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911111111111112"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Making a pipeline to make things easier to work with\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train, y_train) \n",
    "\n",
    "import numpy as np\n",
    "predicted = text_clf.predict(X_train)\n",
    "np.mean(predicted == y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Games']\n",
      "Games\n",
      "['Games']\n",
      "Programming\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(clf_tfidf.predict(count_vect.transform([df['Text'][150]])))\n",
    "#print([df['Text'][1]])\n",
    "print(df['Category'][150])\n",
    "#print(y_test)\n",
    "# X_test: 208, 188, 12 (Programming)\n",
    "print(clf_tfidf.predict(count_vect.transform([df['Text'][188]])))\n",
    "print(df['Category'][188])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.93333333 0.93333333 0.93333333 1.\n",
      " 0.9        0.96666667 1.         0.93333333]\n",
      "Accuracy using 10-fold cross-validation: 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# also evaluate accuracy using 10-fold cross validation\n",
    "# Here I should send in ALL values, not just train or test??\n",
    "#KFold?\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "#clf = <any classifier>\n",
    "X_all_counts = count_vect.transform(df['Text'])\n",
    "\n",
    "score_array = cross_val_score(clf, X_all_counts, df['Category'], cv=k_fold, n_jobs=1)\n",
    "print(score_array)\n",
    "avg_score = np.mean(score_array)\n",
    "\n",
    "print(\"Accuracy using 10-fold cross-validation: \" + str(avg_score))\n",
    "\n",
    "#print(LinearClf.score(X_all_counts, df['Category']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC() - Linear Support Vector Classifier\n",
    "------------\n",
    "From the docs:\n",
    "\n",
    "*Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.*\n",
    "\n",
    "Mostly same procedure as above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Programming']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. LinearSVC with no tf.idf\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Category'], random_state = 0)\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "LinearClf = LinearSVC(random_state=0, tol=1e-5, max_iter=3000)\n",
    "LinearClf.fit(X_train_counts, y_train)\n",
    "\n",
    "#print(LinearClf.coef_)\n",
    "#print(LinearClf.intercept_)\n",
    "print(LinearClf.predict(count_vect.transform([df['Text'][188]])))\n",
    "#print(LinearClf.predict(vectorizer.transform([df['Text'][0]])))\n",
    "#print(count_vect.transform([df['Text'][188]]))\n",
    "LinearClf.score(X_train_counts, y_train)\n",
    "#LinearClf.score(X_test_counts, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93333333 0.93333333 0.93333333 0.86666667 0.86666667 0.93333333\n",
      " 0.86666667 0.96666667 0.9        0.93333333]\n",
      "Accuracy using 10-fold cross-validation: 0.9133333333333334\n"
     ]
    }
   ],
   "source": [
    "# also evaluate accuracy using 10-fold cross validation\n",
    "# Here I should send in ALL values, not just train or test?\n",
    "#KFold?\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "#clf = <any classifier>\n",
    "X_all_counts = count_vect.transform(df['Text'])\n",
    "\n",
    "score_array = cross_val_score(LinearClf, X_all_counts, df['Category'], cv=k_fold, n_jobs=1)\n",
    "print(score_array)\n",
    "avg_score = np.mean(score_array)\n",
    "print(\"Accuracy using 10-fold cross-validation: \" + str(avg_score))\n",
    "\n",
    "#print(LinearClf.score(X_all_counts, df['Category']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93333333 0.93333333 0.93333333 0.86666667 0.86666667 0.93333333\n",
      " 0.86666667 0.96666667 0.9        0.93333333]\n",
      "Accuracy using 10-fold cross-validation: 0.9133333333333334\n",
      "0.9766666666666667\n"
     ]
    }
   ],
   "source": [
    "#4. LinearSVC with tf.idf\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Category'], random_state = 0)\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "#LinearClf2 = LinearSVC(random_state=0, tol=1e-5)\n",
    "LinearClf2 = LinearSVC(random_state=0, tol=1e-5).fit(X_train_tfidf, y_train)\n",
    "LinearClf2.score(X_train_tfidf, y_train)\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "#clf = <any classifier>\n",
    "\n",
    "X_all_counts = count_vect.transform(df['Text'])\n",
    "\n",
    "score_array = cross_val_score(LinearClf2, X_all_counts, df['Category'], cv=k_fold, n_jobs=1)\n",
    "# I should get different scores here, because I'm using TF.IDF\n",
    "# The model LinearClf2 should be different than the earlier\n",
    "print(score_array)\n",
    "avg_score = np.mean(score_array)\n",
    "print(\"Accuracy using 10-fold cross-validation: \" + str(avg_score))\n",
    "print(LinearClf2.score(X_all_counts, df['Category']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
